{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto EAF - Notebook Refactorizado\n",
    "\n",
    "## Electric Arc Furnace - Predicción de Temperatura y Composición Química\n",
    "\n",
    "Este notebook refactorizado organiza el código en pipelines claros y separados:\n",
    "- **Parte 3**: Pipeline de Temperatura (Secuencial)\n",
    "- **Parte 3.5**: Pipeline Químico (Estático)\n",
    "- **Parte 4**: Modelo de Temperatura con XGBoost (Implementado)\n",
    "- **Parte 5**: Modelo Químico Desempaquetado (Bloques Secuenciales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PARTE 1: Configuración Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INSTALACIÓN DE DEPENDENCIAS\n",
    "# =============================================================================\n",
    "!pip install -q pandas numpy matplotlib seaborn scikit-learn xgboost joblib kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import logging\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import kagglehub\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    force=True\n",
    ")\n",
    "logger = logging.getLogger('EAF_Notebook')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "print(\"Imports completados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACIÓN DE DIRECTORIOS\n",
    "# =============================================================================\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "DIRECTORIES = {\n",
    "    'DATA_RAW': PROJECT_ROOT / 'data' / 'raw',\n",
    "    'DATA_PROCESSED': PROJECT_ROOT / 'data' / 'processed',\n",
    "    'MODELS': PROJECT_ROOT / 'models',\n",
    "    'CHEMICAL_RESULTS': PROJECT_ROOT / 'models' / 'chemical_results'\n",
    "}\n",
    "\n",
    "for dir_name, dir_path in DIRECTORIES.items():\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_RAW = DIRECTORIES['DATA_RAW']\n",
    "DATA_PROCESSED = DIRECTORIES['DATA_PROCESSED']\n",
    "MODELS_DIR = DIRECTORIES['MODELS']\n",
    "CHEMICAL_RESULTS_DIR = DIRECTORIES['CHEMICAL_RESULTS']\n",
    "\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "print(f\"DATA_RAW: {DATA_RAW}\")\n",
    "print(f\"DATA_PROCESSED: {DATA_PROCESSED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PARTE 2: Ingesta de Datos y Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DESCARGA DE DATOS DESDE KAGGLE\n",
    "# =============================================================================\n",
    "KAGGLE_DATASET = \"yuriykatser/industrial-data-from-the-arc-furnace\"\n",
    "\n",
    "ARCHIVOS_ESPERADOS = [\n",
    "    \"eaf_transformer.csv\",\n",
    "    \"basket_charged.csv\",\n",
    "    \"eaf_temp.csv\",\n",
    "    \"eaf_final_chemical_measurements.csv\",\n",
    "    \"eaf_added_materials.csv\",\n",
    "    \"inj_mat.csv\",\n",
    "    \"eaf_gaslance_mat.csv\",\n",
    "    \"lf_initial_chemical_measurements.csv\",\n",
    "    \"ladle_tapping.csv\",\n",
    "    \"lf_added_materials.csv\",\n",
    "    \"ferro.csv\"\n",
    "]\n",
    "\n",
    "faltan_datos = any(not (DATA_RAW / f).exists() for f in ARCHIVOS_ESPERADOS)\n",
    "\n",
    "if faltan_datos:\n",
    "    print(f\"Descargando {KAGGLE_DATASET}...\")\n",
    "    try:\n",
    "        cached_path = Path(kagglehub.dataset_download(KAGGLE_DATASET))\n",
    "        DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "        for archivo in ARCHIVOS_ESPERADOS:\n",
    "            shutil.copy2(cached_path / archivo, DATA_RAW / archivo)\n",
    "        print(\"Descarga completada.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la descarga: {e}\")\n",
    "        raise\n",
    "else:\n",
    "    print(\"Datos ya disponibles en data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FUNCIÓN DE CARGA ESTANDARIZADA\n",
    "# =============================================================================\n",
    "def load_standardized(filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga un CSV y estandariza los nombres de columnas.\n",
    "    Detecta y convierte formatos numéricos europeos (coma decimal).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath, low_memory=False)\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    \n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if df[col].astype(str).str.match(r'^-?\\d+,\\d+$').any():\n",
    "            df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Función load_standardized() definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FUNCIONES DE AGREGACIÓN DE SERIES TEMPORALES\n",
    "# =============================================================================\n",
    "\n",
    "def aggregate_gas_data(df_gas: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Agrega datos de gas lance por colada (último valor).\"\"\"\n",
    "    df = df_gas.copy()\n",
    "    cols_gas = ['o2_amount', 'gas_amount']\n",
    "    for col in cols_gas:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df['revtime'] = pd.to_datetime(\n",
    "        df['revtime'].astype(str).str.replace(',', '.', regex=False),\n",
    "        format='%Y-%m-%d %H:%M:%S.%f', errors='coerce'\n",
    "    )\n",
    "    df = df.sort_values('revtime')\n",
    "    return df.groupby('heatid').last()[cols_gas].rename(columns={\n",
    "        'o2_amount': 'total_o2_lance',\n",
    "        'gas_amount': 'total_gas_lance'\n",
    "    })\n",
    "\n",
    "\n",
    "def aggregate_injection_data(df_inj: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Agrega datos de inyección de carbón por colada (último valor).\"\"\"\n",
    "    df = df_inj.copy()\n",
    "    df['inj_amount_carbon'] = pd.to_numeric(df['inj_amount_carbon'], errors='coerce')\n",
    "    df['revtime'] = pd.to_datetime(\n",
    "        df['revtime'].astype(str).str.replace(',', '.', regex=False),\n",
    "        format='%Y-%m-%d %H:%M:%S.%f', errors='coerce'\n",
    "    )\n",
    "    df = df.sort_values('revtime')\n",
    "    return df.groupby('heatid').last()[['inj_amount_carbon']].rename(\n",
    "        columns={'inj_amount_carbon': 'total_injected_carbon'}\n",
    "    )\n",
    "\n",
    "\n",
    "def aggregate_transformer_data(df_transformer: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Agrega datos del transformador por colada (energía total).\"\"\"\n",
    "    df = df_transformer.copy()\n",
    "    \n",
    "    def parse_duration(duration_str):\n",
    "        try:\n",
    "            parts = str(duration_str).strip().split(':')\n",
    "            if len(parts) == 2:\n",
    "                return float(parts[0].strip()) + float(parts[1].strip()) / 60.0\n",
    "            return 0.0\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    df['duration_minutes'] = df['duration'].apply(parse_duration)\n",
    "    df['mw'] = pd.to_numeric(df['mw'], errors='coerce').fillna(0)\n",
    "    df['energy'] = df['mw'] * df['duration_minutes']\n",
    "    \n",
    "    return df.groupby('heatid').agg({\n",
    "        'energy': 'sum',\n",
    "        'duration_minutes': 'sum'\n",
    "    }).rename(columns={'energy': 'total_energy', 'duration_minutes': 'total_duration'})\n",
    "\n",
    "\n",
    "def aggregate_charged_amount(df_ladle: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Agrega cantidad total de material cargado por colada.\"\"\"\n",
    "    df = df_ladle.copy()\n",
    "    df['charge_amount'] = pd.to_numeric(df['charge_amount'], errors='coerce').fillna(0)\n",
    "    return df.groupby('heatid').agg({'charge_amount': 'sum'}).rename(\n",
    "        columns={'charge_amount': 'total_charged_amount'}\n",
    "    )\n",
    "\n",
    "\n",
    "def pivot_materials(df_ladle: pd.DataFrame, top_n: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"Pivota materiales agregados (top N más frecuentes).\"\"\"\n",
    "    df = df_ladle.copy()\n",
    "    df['charge_amount'] = pd.to_numeric(df['charge_amount'], errors='coerce')\n",
    "    top_materials = df['mat_code'].value_counts().head(top_n).index\n",
    "    df_filtered = df[df['mat_code'].isin(top_materials)]\n",
    "    \n",
    "    return df_filtered.pivot_table(\n",
    "        index='heatid',\n",
    "        columns='mat_code',\n",
    "        values='charge_amount',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    ).add_prefix('added_mat_')\n",
    "\n",
    "\n",
    "print(\"Funciones de agregación definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FUNCIÓN PARA CONSTRUIR DATASET MAESTRO DE VARIABLES ESTÁTICAS\n",
    "# =============================================================================\n",
    "\n",
    "def build_master_dataset(data_raw_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construye el dataset maestro con variables estáticas por colada.\n",
    "    Incluye: energía, materiales, gases, etc.\n",
    "    \"\"\"\n",
    "    logger.info(\"Construyendo dataset maestro...\")\n",
    "    \n",
    "    # Cargar archivos fuente\n",
    "    df_transformer = load_standardized(data_raw_path / \"eaf_transformer.csv\")\n",
    "    df_gas = load_standardized(data_raw_path / \"eaf_gaslance_mat.csv\")\n",
    "    df_inj = load_standardized(data_raw_path / \"inj_mat.csv\")\n",
    "    df_ladle = load_standardized(data_raw_path / \"ladle_tapping.csv\")\n",
    "    \n",
    "    # Agregar datos\n",
    "    grp_transformer = aggregate_transformer_data(df_transformer)\n",
    "    grp_gas = aggregate_gas_data(df_gas)\n",
    "    grp_inj = aggregate_injection_data(df_inj)\n",
    "    grp_charged = aggregate_charged_amount(df_ladle)\n",
    "    pivot_ladle = pivot_materials(df_ladle, top_n=10)\n",
    "    \n",
    "    # Crear base con todos los heatids únicos\n",
    "    all_heatids = set(grp_transformer.index) | set(grp_gas.index) | set(grp_inj.index)\n",
    "    df_master = pd.DataFrame({'heatid': list(all_heatids)})\n",
    "    \n",
    "    # Merge de todos los componentes\n",
    "    df_master = df_master.merge(grp_transformer, on='heatid', how='left')\n",
    "    df_master = df_master.merge(grp_gas, on='heatid', how='left')\n",
    "    df_master = df_master.merge(grp_inj, on='heatid', how='left')\n",
    "    df_master = df_master.merge(grp_charged, on='heatid', how='left')\n",
    "    df_master = df_master.merge(pivot_ladle, on='heatid', how='left')\n",
    "    \n",
    "    # Rellenar nulos con 0\n",
    "    df_master = df_master.fillna(0)\n",
    "    \n",
    "    logger.info(f\"Dataset maestro: {df_master.shape}\")\n",
    "    return df_master\n",
    "\n",
    "print(\"Función build_master_dataset() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PARTE 3: PIPELINE DE TEMPERATURA (Secuencial)\n",
    "\n",
    "Este pipeline genera `dataset_sequential_temp.csv` con:\n",
    "- Features dinámicas ($X_t$): temperatura actual, oxidación, posición temporal\n",
    "- Target ($Y_{t+1}$): temperatura del siguiente registro\n",
    "- Variables estáticas: energía, materiales, gases (fusionadas desde dataset maestro)\n",
    "\n",
    "**Pasos:**\n",
    "1. Carga y limpieza de `eaf_temp.csv`\n",
    "2. Filtros físicos (1000-1850°C) y cuantiles\n",
    "3. Ordenamiento por heatid y tiempo\n",
    "4. Generación de features dinámicas\n",
    "5. Generación de target con shift\n",
    "6. Fusión con variables estáticas\n",
    "7. Exportación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Carga y Limpieza de Datos de Temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 1: CARGA DE DATOS DE TEMPERATURA\n",
    "# =============================================================================\n",
    "print(\"=\"*60)\n",
    "print(\"PIPELINE DE TEMPERATURA - INICIO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_temp_seq = load_standardized(DATA_RAW / \"eaf_temp.csv\")\n",
    "\n",
    "print(f\"Archivo cargado: eaf_temp.csv\")\n",
    "print(f\"Shape original: {df_temp_seq.shape}\")\n",
    "print(f\"Columnas: {df_temp_seq.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 2: DETECCIÓN DE COLUMNAS Y CONVERSIÓN DE TIPOS\n",
    "# =============================================================================\n",
    "\n",
    "# Detectar columna de temperatura\n",
    "cols_temp = [c for c in df_temp_seq.columns if 'temp' in c.lower() and 'time' not in c.lower()]\n",
    "col_temp = cols_temp[0] if cols_temp else 'temp'\n",
    "\n",
    "# Detectar columna de tiempo\n",
    "cols_time = [c for c in df_temp_seq.columns if 'time' in c.lower() or 'date' in c.lower()]\n",
    "col_datetime = cols_time[0] if cols_time else 'datetime'\n",
    "\n",
    "# Detectar columna de oxidación\n",
    "cols_ox = [c for c in df_temp_seq.columns if 'ox' in c.lower() or 'o2' in c.lower()]\n",
    "col_oxidation = cols_ox[0] if cols_ox else None\n",
    "\n",
    "print(f\"Columna de temperatura: {col_temp}\")\n",
    "print(f\"Columna de tiempo: {col_datetime}\")\n",
    "print(f\"Columna de oxidación: {col_oxidation}\")\n",
    "\n",
    "# Convertir tipos\n",
    "df_temp_seq[col_temp] = pd.to_numeric(df_temp_seq[col_temp], errors='coerce')\n",
    "df_temp_seq[col_datetime] = pd.to_datetime(\n",
    "    df_temp_seq[col_datetime].astype(str).str.replace(',', '.', regex=False),\n",
    "    errors='coerce'\n",
    ")\n",
    "if col_oxidation:\n",
    "    df_temp_seq[col_oxidation] = pd.to_numeric(df_temp_seq[col_oxidation], errors='coerce')\n",
    "\n",
    "print(f\"\\nEstadísticas de temperatura (sin filtrar):\")\n",
    "print(df_temp_seq[col_temp].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 3: FILTROS DE LIMPIEZA (CRÍTICO)\n",
    "# =============================================================================\n",
    "filas_inicial = len(df_temp_seq)\n",
    "print(f\"Filas iniciales: {filas_inicial:,}\")\n",
    "\n",
    "# FILTRO 1: Rango físico (1000-1850°C)\n",
    "TEMP_MIN_FISICA = 1000\n",
    "TEMP_MAX_FISICA = 1850\n",
    "\n",
    "mask_fisica = (df_temp_seq[col_temp] >= TEMP_MIN_FISICA) & (df_temp_seq[col_temp] <= TEMP_MAX_FISICA)\n",
    "df_temp_seq = df_temp_seq[mask_fisica].copy()\n",
    "\n",
    "filas_despues_fisica = len(df_temp_seq)\n",
    "print(f\"Filtro físico ({TEMP_MIN_FISICA}-{TEMP_MAX_FISICA}°C): {filas_inicial - filas_despues_fisica:,} filas eliminadas\")\n",
    "\n",
    "# FILTRO 2: Cuantiles (0.5% extremos)\n",
    "QUANTILE_LOWER = 0.005\n",
    "QUANTILE_UPPER = 0.995\n",
    "\n",
    "q_low = df_temp_seq[col_temp].quantile(QUANTILE_LOWER)\n",
    "q_high = df_temp_seq[col_temp].quantile(QUANTILE_UPPER)\n",
    "\n",
    "mask_quantile = (df_temp_seq[col_temp] >= q_low) & (df_temp_seq[col_temp] <= q_high)\n",
    "df_temp_seq = df_temp_seq[mask_quantile].copy()\n",
    "\n",
    "filas_final = len(df_temp_seq)\n",
    "print(f\"Filtro cuantil ({QUANTILE_LOWER:.1%}-{QUANTILE_UPPER:.1%}): {filas_despues_fisica - filas_final:,} filas eliminadas\")\n",
    "print(f\"  Rango aceptado: [{q_low:.1f}, {q_high:.1f}] °C\")\n",
    "\n",
    "print(f\"\\nTotal eliminado: {filas_inicial - filas_final:,} ({100*(filas_inicial - filas_final)/filas_inicial:.2f}%)\")\n",
    "print(f\"Filas finales: {filas_final:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ordenamiento y Generación de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 4: ORDENAMIENTO ESTRICTO\n",
    "# =============================================================================\n",
    "\n",
    "# Eliminar nulos en columnas críticas\n",
    "df_temp_seq = df_temp_seq.dropna(subset=['heatid', col_datetime, col_temp])\n",
    "\n",
    "# Ordenar por heatid y tiempo (CRÍTICO para series temporales)\n",
    "df_temp_seq = df_temp_seq.sort_values(['heatid', col_datetime]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset ordenado por heatid y {col_datetime}\")\n",
    "print(f\"Shape: {df_temp_seq.shape}\")\n",
    "print(f\"Coladas únicas: {df_temp_seq['heatid'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 5: CREACIÓN DE FEATURES DINÁMICAS (X_t)\n",
    "# =============================================================================\n",
    "\n",
    "# Feature 1: Temperatura actual\n",
    "df_temp_seq['temp_actual'] = df_temp_seq[col_temp]\n",
    "\n",
    "# Feature 2: Oxidación actual\n",
    "if col_oxidation:\n",
    "    df_temp_seq['oxidacion_actual'] = df_temp_seq[col_oxidation].fillna(0)\n",
    "else:\n",
    "    df_temp_seq['oxidacion_actual'] = 0\n",
    "\n",
    "# Feature 3: Número de medición dentro de la colada\n",
    "df_temp_seq['num_medicion'] = df_temp_seq.groupby('heatid').cumcount() + 1\n",
    "\n",
    "# Feature 4: Tiempo transcurrido desde inicio (minutos)\n",
    "df_temp_seq['tiempo_desde_inicio'] = df_temp_seq.groupby('heatid')[col_datetime].transform(\n",
    "    lambda x: (x - x.min()).dt.total_seconds() / 60\n",
    ")\n",
    "\n",
    "print(\"Features dinámicas creadas:\")\n",
    "print(\"  - temp_actual\")\n",
    "print(\"  - oxidacion_actual\")\n",
    "print(\"  - num_medicion\")\n",
    "print(\"  - tiempo_desde_inicio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 6: GENERACIÓN DEL TARGET (Y_t) - TEMPERATURA SIGUIENTE\n",
    "# =============================================================================\n",
    "\n",
    "# Target: Temperatura del siguiente momento temporal (shift negativo)\n",
    "df_temp_seq['target_temp_next'] = df_temp_seq.groupby('heatid')[col_temp].shift(-1)\n",
    "\n",
    "# Datetime del siguiente registro (para calcular horizonte)\n",
    "df_temp_seq['datetime_next'] = df_temp_seq.groupby('heatid')[col_datetime].shift(-1)\n",
    "\n",
    "# Horizonte temporal en minutos\n",
    "df_temp_seq['horizonte_minutos'] = (\n",
    "    df_temp_seq['datetime_next'] - df_temp_seq[col_datetime]\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "print(\"Target generado: target_temp_next\")\n",
    "print(f\"Estadísticas del horizonte temporal:\")\n",
    "print(df_temp_seq['horizonte_minutos'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 7: LIMPIEZA DE BORDES\n",
    "# =============================================================================\n",
    "\n",
    "filas_antes = len(df_temp_seq)\n",
    "n_coladas = df_temp_seq['heatid'].nunique()\n",
    "\n",
    "# Eliminar filas donde target es NaN (últimos registros de cada colada)\n",
    "df_temp_seq = df_temp_seq.dropna(subset=['target_temp_next'])\n",
    "\n",
    "# Filtrar horizontes anómalos\n",
    "mask_horizonte_valido = (df_temp_seq['horizonte_minutos'] > 0) & (df_temp_seq['horizonte_minutos'] < 120)\n",
    "df_temp_seq = df_temp_seq[mask_horizonte_valido]\n",
    "\n",
    "filas_despues = len(df_temp_seq)\n",
    "print(f\"Filas antes: {filas_antes:,}\")\n",
    "print(f\"Filas después de limpieza de bordes: {filas_despues:,}\")\n",
    "print(f\"Eliminadas: {filas_antes - filas_despues:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Fusión con Variables Estáticas y Exportación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 8: FUSIÓN CON DATASET MAESTRO\n",
    "# =============================================================================\n",
    "\n",
    "# Construir dataset maestro de variables estáticas\n",
    "print(\"Construyendo dataset maestro...\")\n",
    "df_master = build_master_dataset(DATA_RAW)\n",
    "\n",
    "print(f\"Dataset maestro: {df_master.shape}\")\n",
    "print(f\"Dataset secuencial: {df_temp_seq.shape}\")\n",
    "\n",
    "# Fusionar (one-to-many: variables estáticas se replican por cada medición)\n",
    "df_sequential = df_temp_seq.merge(df_master, on='heatid', how='left')\n",
    "\n",
    "print(f\"Dataset fusionado: {df_sequential.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 9: PREPARACIÓN FINAL Y EXPORTACIÓN\n",
    "# =============================================================================\n",
    "\n",
    "# Rellenar nulos con 0\n",
    "df_sequential = df_sequential.fillna(0)\n",
    "\n",
    "# Eliminar columnas auxiliares\n",
    "cols_drop = ['datetime_next', col_datetime, 'datetime', 'positionrow', 'filter_key_date', 'measure_time']\n",
    "cols_drop = [c for c in cols_drop if c in df_sequential.columns]\n",
    "df_sequential = df_sequential.drop(columns=cols_drop)\n",
    "\n",
    "# Eliminar columna de temperatura original si existe\n",
    "if col_temp in df_sequential.columns and col_temp != 'temp_actual':\n",
    "    df_sequential = df_sequential.drop(columns=[col_temp])\n",
    "\n",
    "# Reorganizar columnas\n",
    "target_col = 'target_temp_next'\n",
    "cols_order = ['heatid'] + [c for c in df_sequential.columns if c not in ['heatid', target_col]] + [target_col]\n",
    "df_sequential = df_sequential[cols_order]\n",
    "\n",
    "# GUARDAR\n",
    "output_path = DATA_PROCESSED / \"dataset_sequential_temp.csv\"\n",
    "df_sequential.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PIPELINE DE TEMPERATURA - COMPLETADO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Archivo: {output_path}\")\n",
    "print(f\"Shape: {df_sequential.shape}\")\n",
    "print(f\"Coladas únicas: {df_sequential['heatid'].nunique()}\")\n",
    "print(f\"Mediciones por colada (promedio): {len(df_sequential) / df_sequential['heatid'].nunique():.1f}\")\n",
    "print(f\"\\nColumnas ({len(df_sequential.columns)}):\")\n",
    "print(df_sequential.columns.tolist()[:15], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PARTE 3.5: PIPELINE QUÍMICO (Estático)\n",
    "\n",
    "Este pipeline genera `dataset_final_chemical.csv` con:\n",
    "- Inputs: variables del proceso (materiales, energía, gases)\n",
    "- Targets: composición química final (C, Mn, Si, P, S, Cu, Cr, Mo, Ni)\n",
    "\n",
    "**Pasos:**\n",
    "1. Carga de `eaf_final_chemical_measurements.csv`\n",
    "2. Extracción de targets químicos\n",
    "3. Fusión con dataset maestro\n",
    "4. Limpieza y exportación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Carga de Mediciones Químicas Finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 1: CARGA DE DATOS QUÍMICOS FINALES\n",
    "# =============================================================================\n",
    "print(\"=\"*60)\n",
    "print(\"PIPELINE QUÍMICO - INICIO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_chem_final = load_standardized(DATA_RAW / \"eaf_final_chemical_measurements.csv\")\n",
    "\n",
    "print(f\"Archivo cargado: eaf_final_chemical_measurements.csv\")\n",
    "print(f\"Shape: {df_chem_final.shape}\")\n",
    "print(f\"Columnas: {df_chem_final.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 2: EXTRACCIÓN DE TARGETS QUÍMICOS\n",
    "# =============================================================================\n",
    "\n",
    "# Elementos químicos a extraer como targets\n",
    "chemical_elements = ['valc', 'valmn', 'valsi', 'valp', 'vals', 'valcu', 'valcr', 'valmo', 'valni']\n",
    "\n",
    "# Verificar disponibilidad\n",
    "available_elements = [col for col in chemical_elements if col in df_chem_final.columns]\n",
    "print(f\"Elementos disponibles: {available_elements}\")\n",
    "\n",
    "# Seleccionar heatid y elementos\n",
    "cols_to_select = ['heatid'] + available_elements\n",
    "df_targets = df_chem_final[cols_to_select].copy()\n",
    "\n",
    "# Convertir a numérico\n",
    "for col in available_elements:\n",
    "    df_targets[col] = pd.to_numeric(df_targets[col], errors='coerce')\n",
    "\n",
    "# Renombrar con prefijo target_\n",
    "rename_dict = {col: f'target_{col}' for col in available_elements}\n",
    "df_targets = df_targets.rename(columns=rename_dict)\n",
    "\n",
    "# Eliminar duplicados por heatid\n",
    "df_targets = df_targets.drop_duplicates(subset=['heatid'], keep='last')\n",
    "\n",
    "print(f\"\\nTargets extraídos: {len(df_targets)} coladas\")\n",
    "print(df_targets.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Fusión con Dataset Maestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 3: GENERAR/REUTILIZAR DATASET MAESTRO\n",
    "# =============================================================================\n",
    "\n",
    "# Reutilizar df_master si ya existe, sino generarlo\n",
    "if 'df_master' not in dir() or df_master is None:\n",
    "    print(\"Generando dataset maestro...\")\n",
    "    df_master = build_master_dataset(DATA_RAW)\n",
    "else:\n",
    "    print(\"Reutilizando df_master existente.\")\n",
    "\n",
    "print(f\"Dataset maestro: {df_master.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 4: FUSIÓN DE INPUTS CON TARGETS\n",
    "# =============================================================================\n",
    "\n",
    "# Inner join: solo coladas con datos completos\n",
    "df_chemical = df_master.merge(df_targets, on='heatid', how='inner')\n",
    "\n",
    "print(f\"Dataset maestro: {len(df_master)} coladas\")\n",
    "print(f\"Targets químicos: {len(df_targets)} coladas\")\n",
    "print(f\"Dataset fusionado: {len(df_chemical)} coladas\")\n",
    "print(f\"Pérdida por merge: {len(df_master) - len(df_chemical)} coladas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Limpieza Final y Exportación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 5: LIMPIEZA FINAL Y GUARDADO\n",
    "# =============================================================================\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "cols_drop = ['datetime', 'positionrow', 'filter_key_date', 'measure_time']\n",
    "df_chemical = df_chemical.drop(columns=[c for c in cols_drop if c in df_chemical.columns])\n",
    "\n",
    "# Identificar columnas target\n",
    "target_cols = [c for c in df_chemical.columns if c.startswith('target_')]\n",
    "\n",
    "# Eliminar filas donde TODOS los targets son nulos\n",
    "rows_before = len(df_chemical)\n",
    "df_chemical = df_chemical.dropna(subset=target_cols, how='all')\n",
    "print(f\"Filas eliminadas (todos targets nulos): {rows_before - len(df_chemical)}\")\n",
    "\n",
    "# Rellenar nulos con 0\n",
    "df_chemical = df_chemical.fillna(0)\n",
    "\n",
    "# GUARDAR\n",
    "output_path_chemical = DATA_PROCESSED / \"dataset_final_chemical.csv\"\n",
    "df_chemical.to_csv(output_path_chemical, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE QUÍMICO - COMPLETADO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Archivo: {output_path_chemical}\")\n",
    "print(f\"Shape: {df_chemical.shape}\")\n",
    "print(f\"Features de input: {len(df_chemical.columns) - len(target_cols)}\")\n",
    "print(f\"Variables target: {len(target_cols)}\")\n",
    "print(f\"\\nTargets: {target_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANÁLISIS EXPLORATORIO RÁPIDO\n",
    "# =============================================================================\n",
    "print(\"\\nEstadísticas de targets químicos:\")\n",
    "print(df_chemical[target_cols].describe().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PARTE 4: MODELO DE TEMPERATURA (XGBoost)\n",
    "\n",
    "Implementación del modelo de predicción de temperatura usando:\n",
    "- **XGBoost Regressor**\n",
    "- **GroupShuffleSplit** para validación por coladas (evita data leakage)\n",
    "- Métricas: RMSE, R²\n",
    "- Visualización: Predicción vs Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Carga del Dataset Secuencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CARGA DEL DATASET SECUENCIAL\n",
    "# =============================================================================\n",
    "print(\"=\"*60)\n",
    "print(\"MODELO DE TEMPERATURA - INICIO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar dataset\n",
    "df_temp = pd.read_csv(DATA_PROCESSED / \"dataset_sequential_temp.csv\")\n",
    "\n",
    "print(f\"Dataset cargado: {df_temp.shape}\")\n",
    "print(f\"Coladas únicas: {df_temp['heatid'].nunique()}\")\n",
    "print(f\"\\nColumnas:\")\n",
    "print(df_temp.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Preparación de Features y Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREPARACIÓN DE FEATURES Y TARGET\n",
    "# =============================================================================\n",
    "\n",
    "# Target\n",
    "TARGET_COL = 'target_temp_next'\n",
    "\n",
    "# Features: todas las columnas excepto heatid y target\n",
    "feature_cols = [c for c in df_temp.columns if c not in ['heatid', TARGET_COL]]\n",
    "\n",
    "X = df_temp[feature_cols]\n",
    "y = df_temp[TARGET_COL]\n",
    "groups = df_temp['heatid']  # Para GroupShuffleSplit\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Muestras: {len(X)}\")\n",
    "print(f\"Target: {TARGET_COL}\")\n",
    "print(f\"\\nEstadísticas del target:\")\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Split Train/Test con GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPLIT TRAIN/TEST CON GROUPSHUFFLESPLIT\n",
    "# =============================================================================\n",
    "# IMPORTANTE: Usamos GroupShuffleSplit para que todas las mediciones de una\n",
    "# misma colada estén completamente en train o en test, nunca mezcladas.\n",
    "# Esto evita DATA LEAKAGE.\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Configuración del split\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "# Obtener índices de train/test\n",
    "train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "# Verificar que no hay coladas mezcladas\n",
    "train_heats = set(groups.iloc[train_idx])\n",
    "test_heats = set(groups.iloc[test_idx])\n",
    "overlap = train_heats & test_heats\n",
    "\n",
    "print(f\"Split Train/Test (GroupShuffleSplit):\")\n",
    "print(f\"  - Train: {len(X_train):,} muestras ({len(train_heats)} coladas)\")\n",
    "print(f\"  - Test:  {len(X_test):,} muestras ({len(test_heats)} coladas)\")\n",
    "print(f\"  - Coladas superpuestas: {len(overlap)} (debe ser 0)\")\n",
    "\n",
    "if len(overlap) > 0:\n",
    "    print(\"  ADVERTENCIA: Hay coladas mezcladas entre train y test!\")\n",
    "else:\n",
    "    print(\"  Sin data leakage por coladas mezcladas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Entrenamiento del Modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENTRENAMIENTO DEL MODELO XGBOOST\n",
    "# =============================================================================\n",
    "\n",
    "# Hiperparámetros\n",
    "HYPERPARAMS = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "print(\"Entrenando XGBoost Regressor...\")\n",
    "print(f\"Hiperparámetros: {HYPERPARAMS}\")\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "model_temp = XGBRegressor(**HYPERPARAMS)\n",
    "model_temp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Entrenamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREDICCIÓN Y MÉTRICAS\n",
    "# =============================================================================\n",
    "\n",
    "# Predicción\n",
    "y_pred = model_temp.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MÉTRICAS DE EVALUACIÓN - MODELO DE TEMPERATURA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  RMSE: {rmse:.4f} °C\")\n",
    "print(f\"  R²:   {r2:.4f}\")\n",
    "print(f\"  MAE:  {mae:.4f} °C\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Interpretación\n",
    "if r2 > 0.8:\n",
    "    print(\"Excelente capacidad predictiva.\")\n",
    "elif r2 > 0.6:\n",
    "    print(\"Buena capacidad predictiva.\")\n",
    "elif r2 > 0.3:\n",
    "    print(\"Capacidad predictiva moderada.\")\n",
    "else:\n",
    "    print(\"Capacidad predictiva baja. Considerar ajustes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Visualización: Predicción vs Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GRÁFICA: PREDICCIÓN VS REAL\n",
    "# =============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(y_test, y_pred, alpha=0.3, color='steelblue', s=10)\n",
    "\n",
    "# Línea de predicción perfecta\n",
    "min_val = min(y_test.min(), y_pred.min())\n",
    "max_val = max(y_test.max(), y_pred.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Predicción Perfecta')\n",
    "\n",
    "# Configuración\n",
    "ax.set_xlabel('Temperatura Real (°C)', fontsize=12)\n",
    "ax.set_ylabel('Temperatura Predicha (°C)', fontsize=12)\n",
    "ax.set_title('Modelo de Temperatura - Predicción vs Real', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Métricas en recuadro\n",
    "textstr = f'RMSE: {rmse:.2f}°C\\nR²: {r2:.4f}\\nMAE: {mae:.2f}°C'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Gráfica generada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Importancia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTANCIA DE FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "# Obtener importancias\n",
    "importances = model_temp.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Top 15 features\n",
    "top_n = 15\n",
    "top_features = feature_importance_df.head(top_n)\n",
    "\n",
    "# Gráfica\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, top_n))\n",
    "bars = ax.barh(range(top_n), top_features['importance'].values[::-1], color=colors)\n",
    "ax.set_yticks(range(top_n))\n",
    "ax.set_yticklabels(top_features['feature'].values[::-1])\n",
    "ax.set_xlabel('Importancia', fontsize=12)\n",
    "ax.set_title(f'Top {top_n} Features Más Importantes - Modelo de Temperatura', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 features más importantes:\")\n",
    "print(feature_importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR MODELO\n",
    "# =============================================================================\n",
    "\n",
    "model_path = MODELS_DIR / \"model_temperature_xgboost.joblib\"\n",
    "joblib.dump(model_temp, model_path)\n",
    "\n",
    "# Guardar metadata\n",
    "metadata = {\n",
    "    'model_type': 'XGBoost Regressor',\n",
    "    'hyperparameters': HYPERPARAMS,\n",
    "    'metrics': {'RMSE': rmse, 'R2': r2, 'MAE': mae},\n",
    "    'features': feature_cols,\n",
    "    'n_train_samples': len(X_train),\n",
    "    'n_test_samples': len(X_test),\n",
    "    'n_train_heats': len(train_heats),\n",
    "    'n_test_heats': len(test_heats)\n",
    "}\n",
    "\n",
    "with open(MODELS_DIR / \"model_temperature_metadata.json\", 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(f\"Modelo guardado: {model_path}\")\n",
    "print(f\"Metadata guardada: {MODELS_DIR / 'model_temperature_metadata.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PARTE 5: MODELO QUÍMICO (Desempaquetado)\n",
    "\n",
    "Esta sección implementa el entrenamiento de modelos químicos en **bloques secuenciales**\n",
    "para facilitar debugging y modificación de hiperparámetros.\n",
    "\n",
    "**Flujo:**\n",
    "1. Carga y selección de features\n",
    "2. Split Train/Test\n",
    "3. Entrenamiento\n",
    "4. Evaluación\n",
    "5. Visualización\n",
    "\n",
    "**Nota:** Este ejemplo usa `target_valc` (Carbono). Puedes cambiar el target para otros elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Configuración del Elemento a Predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACIÓN DEL MODELO QUÍMICO\n",
    "# =============================================================================\n",
    "\n",
    "# Elemento químico a predecir (cambiar aquí para otros elementos)\n",
    "TARGET_CHEMICAL = 'target_valc'  # Opciones: target_valc, target_valmn, target_valsi, etc.\n",
    "\n",
    "# Lista de todos los targets disponibles\n",
    "CHEMICAL_TARGETS = [\n",
    "    'target_valc',   # Carbono\n",
    "    'target_valmn',  # Manganeso\n",
    "    'target_valsi',  # Silicio\n",
    "    'target_valp',   # Fósforo\n",
    "    'target_vals',   # Azufre\n",
    "    'target_valcu',  # Cobre\n",
    "    'target_valcr',  # Cromo\n",
    "    'target_valmo',  # Molibdeno\n",
    "    'target_valni'   # Níquel\n",
    "]\n",
    "\n",
    "# Hiperparámetros\n",
    "HYPERPARAMS_CHEM = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "TEST_SIZE_CHEM = 0.2\n",
    "\n",
    "print(f\"Target seleccionado: {TARGET_CHEMICAL}\")\n",
    "print(f\"Elemento: {TARGET_CHEMICAL.replace('target_val', '').upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Carga de Datos y Selección de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 1: CARGA DE DATOS\n",
    "# =============================================================================\n",
    "print(\"=\"*60)\n",
    "print(f\"MODELO QUÍMICO - {TARGET_CHEMICAL.replace('target_val', '').upper()}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_chem = pd.read_csv(DATA_PROCESSED / \"dataset_final_chemical.csv\")\n",
    "\n",
    "print(f\"Dataset cargado: {df_chem.shape}\")\n",
    "print(f\"Columnas: {len(df_chem.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 2: SELECCIÓN DE FEATURES (Evitar Data Leakage)\n",
    "# =============================================================================\n",
    "\n",
    "# Obtener nombre del valor inicial del elemento (para excluirlo)\n",
    "initial_feature = TARGET_CHEMICAL.replace('target_', '')  # ej: 'valc'\n",
    "\n",
    "# Features: excluir heatid, todos los targets, y el valor inicial del elemento actual\n",
    "exclude_cols = ['heatid'] + CHEMICAL_TARGETS + [initial_feature]\n",
    "feature_cols_chem = [c for c in df_chem.columns if c not in exclude_cols]\n",
    "\n",
    "print(f\"Features seleccionadas: {len(feature_cols_chem)}\")\n",
    "print(f\"Excluido '{initial_feature}' para evitar data leakage\")\n",
    "\n",
    "# Verificar que el target existe\n",
    "if TARGET_CHEMICAL not in df_chem.columns:\n",
    "    raise ValueError(f\"Target '{TARGET_CHEMICAL}' no encontrado en el dataset\")\n",
    "\n",
    "print(f\"\\nPrimeras 10 features:\")\n",
    "print(feature_cols_chem[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 3: PREPARACIÓN DE X e Y\n",
    "# =============================================================================\n",
    "\n",
    "X_chem = df_chem[feature_cols_chem].copy()\n",
    "y_chem = df_chem[TARGET_CHEMICAL].copy()\n",
    "\n",
    "# Eliminar filas donde el target es NaN\n",
    "mask_not_null = y_chem.notnull()\n",
    "X_chem = X_chem[mask_not_null]\n",
    "y_chem = y_chem[mask_not_null]\n",
    "\n",
    "print(f\"Muestras después de eliminar NaN: {len(X_chem)}\")\n",
    "\n",
    "# Imputar NaNs en features con 0\n",
    "X_chem = X_chem.fillna(0)\n",
    "\n",
    "# Limpiar infinitos\n",
    "X_chem = X_chem.replace([np.inf, -np.inf], 0)\n",
    "y_chem = y_chem.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "X_chem = X_chem.loc[y_chem.index]\n",
    "\n",
    "print(f\"\\nEstadísticas del target ({TARGET_CHEMICAL}):\")\n",
    "print(y_chem.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 4: SPLIT TRAIN/TEST\n",
    "# =============================================================================\n",
    "\n",
    "X_train_chem, X_test_chem, y_train_chem, y_test_chem = train_test_split(\n",
    "    X_chem, y_chem, \n",
    "    test_size=TEST_SIZE_CHEM, \n",
    "    random_state=HYPERPARAMS_CHEM['random_state']\n",
    ")\n",
    "\n",
    "print(f\"Split Train/Test:\")\n",
    "print(f\"  - Train: {len(X_train_chem)} muestras\")\n",
    "print(f\"  - Test:  {len(X_test_chem)} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 5: ENTRENAMIENTO\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"Entrenando XGBoost para {TARGET_CHEMICAL}...\")\n",
    "print(f\"Hiperparámetros: {HYPERPARAMS_CHEM}\")\n",
    "\n",
    "model_chem = XGBRegressor(**HYPERPARAMS_CHEM)\n",
    "model_chem.fit(X_train_chem, y_train_chem)\n",
    "\n",
    "print(\"Entrenamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 6: PREDICCIÓN Y MÉTRICAS\n",
    "# =============================================================================\n",
    "\n",
    "y_pred_chem = model_chem.predict(X_test_chem)\n",
    "\n",
    "# Métricas\n",
    "rmse_chem = np.sqrt(mean_squared_error(y_test_chem, y_pred_chem))\n",
    "r2_chem = r2_score(y_test_chem, y_pred_chem)\n",
    "mae_chem = mean_absolute_error(y_test_chem, y_pred_chem)\n",
    "\n",
    "element_name = TARGET_CHEMICAL.replace('target_val', '').upper()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"MÉTRICAS - {element_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  RMSE: {rmse_chem:.6f}\")\n",
    "print(f\"  R²:   {r2_chem:.4f}\")\n",
    "print(f\"  MAE:  {mae_chem:.6f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Interpretación\n",
    "if r2_chem < 0:\n",
    "    print(\"ADVERTENCIA: R² negativo. El modelo es peor que predecir la media.\")\n",
    "elif r2_chem < 0.3:\n",
    "    print(\"R² bajo. Considerar ajustar hiperparámetros o features.\")\n",
    "else:\n",
    "    print(f\"Capacidad predictiva {'buena' if r2_chem > 0.6 else 'moderada'}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 7: GRÁFICAS DE VISUALIZACIÓN\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ----- Gráfica 1: Predicción vs Real -----\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test_chem, y_pred_chem, alpha=0.5, color='steelblue', edgecolors='white', linewidth=0.5)\n",
    "\n",
    "# Línea de predicción perfecta\n",
    "min_val = min(y_test_chem.min(), y_pred_chem.min())\n",
    "max_val = max(y_test_chem.max(), y_pred_chem.max())\n",
    "ax1.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Predicción Perfecta')\n",
    "\n",
    "ax1.set_xlabel(f'Valor Real - {element_name} (%)', fontsize=11)\n",
    "ax1.set_ylabel(f'Valor Predicho - {element_name} (%)', fontsize=11)\n",
    "ax1.set_title(f'Predicción vs Real - {element_name}', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Métricas en recuadro\n",
    "textstr = f'RMSE: {rmse_chem:.6f}\\nR²: {r2_chem:.4f}\\nMAE: {mae_chem:.6f}'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "ax1.text(0.05, 0.95, textstr, transform=ax1.transAxes, fontsize=10,\n",
    "         verticalalignment='top', bbox=props)\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ----- Gráfica 2: Importancia de Features -----\n",
    "ax2 = axes[1]\n",
    "\n",
    "importances_chem = model_chem.feature_importances_\n",
    "importance_df_chem = pd.DataFrame({\n",
    "    'feature': feature_cols_chem,\n",
    "    'importance': importances_chem\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "top_n = 15\n",
    "top_features_chem = importance_df_chem.head(top_n)\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, top_n))\n",
    "ax2.barh(range(top_n), top_features_chem['importance'].values[::-1], color=colors)\n",
    "ax2.set_yticks(range(top_n))\n",
    "ax2.set_yticklabels(top_features_chem['feature'].values[::-1], fontsize=9)\n",
    "ax2.set_xlabel('Importancia', fontsize=11)\n",
    "ax2.set_title(f'Top {top_n} Features - {element_name}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PASO 8: GUARDAR RESULTADOS\n",
    "# =============================================================================\n",
    "\n",
    "element_short = TARGET_CHEMICAL.replace('target_', '')\n",
    "\n",
    "# Guardar modelo\n",
    "model_path_chem = MODELS_DIR / f\"model_chemical_{element_short}_xgboost.joblib\"\n",
    "joblib.dump(model_chem, model_path_chem)\n",
    "\n",
    "# Guardar metadata\n",
    "metadata_chem = {\n",
    "    'target': TARGET_CHEMICAL,\n",
    "    'element': element_short,\n",
    "    'model_type': 'XGBoost Regressor',\n",
    "    'hyperparameters': HYPERPARAMS_CHEM,\n",
    "    'metrics': {'RMSE': rmse_chem, 'R2': r2_chem, 'MAE': mae_chem},\n",
    "    'features': feature_cols_chem,\n",
    "    'n_train_samples': len(X_train_chem),\n",
    "    'n_test_samples': len(X_test_chem)\n",
    "}\n",
    "\n",
    "with open(MODELS_DIR / f\"model_chemical_{element_short}_metadata.json\", 'w') as f:\n",
    "    json.dump(metadata_chem, f, indent=4)\n",
    "\n",
    "print(f\"Modelo guardado: {model_path_chem}\")\n",
    "print(f\"Metadata guardada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Entrenamiento para Múltiples Elementos (Opcional)\n",
    "\n",
    "Esta celda entrena modelos para todos los elementos químicos disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENTRENAMIENTO PARA MÚLTIPLES ELEMENTOS (OPCIONAL)\n",
    "# =============================================================================\n",
    "# Descomenta esta celda para entrenar modelos para todos los elementos\n",
    "\n",
    "TRAIN_ALL_ELEMENTS = False  # Cambiar a True para entrenar todos\n",
    "\n",
    "if TRAIN_ALL_ELEMENTS:\n",
    "    results_all = {}\n",
    "    \n",
    "    for target in CHEMICAL_TARGETS:\n",
    "        if target not in df_chem.columns:\n",
    "            print(f\"Saltando {target} - no encontrado en dataset\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Entrenando: {target}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Preparar datos\n",
    "        initial_feat = target.replace('target_', '')\n",
    "        exclude = ['heatid'] + CHEMICAL_TARGETS + [initial_feat]\n",
    "        feat_cols = [c for c in df_chem.columns if c not in exclude]\n",
    "        \n",
    "        X = df_chem[feat_cols].copy()\n",
    "        y = df_chem[target].copy()\n",
    "        \n",
    "        # Limpiar\n",
    "        mask = y.notnull()\n",
    "        X = X[mask].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "        y = y[mask]\n",
    "        \n",
    "        if len(X) < 100:\n",
    "            print(f\"  Insuficientes muestras ({len(X)}), saltando...\")\n",
    "            continue\n",
    "        \n",
    "        # Split\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Entrenar\n",
    "        model = XGBRegressor(**HYPERPARAMS_CHEM)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # Evaluar\n",
    "        y_p = model.predict(X_te)\n",
    "        rmse = np.sqrt(mean_squared_error(y_te, y_p))\n",
    "        r2 = r2_score(y_te, y_p)\n",
    "        \n",
    "        results_all[target] = {'RMSE': rmse, 'R2': r2}\n",
    "        print(f\"  RMSE: {rmse:.6f}, R²: {r2:.4f}\")\n",
    "        \n",
    "        # Guardar\n",
    "        elem = target.replace('target_', '')\n",
    "        joblib.dump(model, MODELS_DIR / f\"model_chemical_{elem}_xgboost.joblib\")\n",
    "    \n",
    "    # Resumen\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESUMEN DE TODOS LOS MODELOS\")\n",
    "    print(\"=\"*60)\n",
    "    for t, m in results_all.items():\n",
    "        print(f\"{t}: RMSE={m['RMSE']:.6f}, R²={m['R2']:.4f}\")\n",
    "else:\n",
    "    print(\"Entrenamiento múltiple desactivado. Cambiar TRAIN_ALL_ELEMENTS = True para activar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resumen Final\n",
    "\n",
    "Este notebook refactorizado incluye:\n",
    "\n",
    "1. **PARTE 3**: Pipeline de Temperatura (Secuencial)\n",
    "   - Genera `dataset_sequential_temp.csv`\n",
    "   - Filtros físicos y cuantiles\n",
    "   - Features dinámicas + estáticas\n",
    "\n",
    "2. **PARTE 3.5**: Pipeline Químico (Estático)\n",
    "   - Genera `dataset_final_chemical.csv`\n",
    "   - Extracción de 9 elementos químicos como targets\n",
    "\n",
    "3. **PARTE 4**: Modelo de Temperatura con XGBoost\n",
    "   - GroupShuffleSplit para evitar data leakage\n",
    "   - Métricas y visualizaciones\n",
    "\n",
    "4. **PARTE 5**: Modelo Químico Desempaquetado\n",
    "   - Bloques secuenciales para debugging\n",
    "   - Fácil modificación de hiperparámetros\n",
    "   - Visualización de importancia de features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
